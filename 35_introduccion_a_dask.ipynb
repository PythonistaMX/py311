{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![img/pythonista.png](img/pythonista.png)](https://www.pythonista.io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducci√≥n a *Dask*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexto: Del an√°lisis local al escalado distribuido\n",
    "\n",
    "En los cap√≠tulos anteriores aprendiste sobre **Polars** y **PyArrow**, que te ofrecen capacidades poderosas para analizar datos en una m√°quina. Sin embargo, cuando tus datos crecen m√°s all√° de lo que pueda caber en la memoria de una computadora, necesitas una estrategia diferente.\n",
    "\n",
    "### ¬øPolars o Dask?\n",
    "\n",
    "| Aspecto | **Polars** | **Dask** |\n",
    "|---------|-----------|----------|\n",
    "| **Tama√±o de datos** | Hasta ~100 GB | >100 GB (terabytes) |\n",
    "| **Localidad de ejecuci√≥n** | Una m√°quina | M√∫ltiples m√°quinas (cl√∫ster) |\n",
    "| **Velocidad (single-machine)** | ‚ö° 3-10x m√°s r√°pido que Pandas | üöÄ Distribuida, puede ser m√°s lenta por overhead |\n",
    "| **Facilidad de uso** | üòä API simple y moderna | üòê M√°s complejo, requiere cluster |\n",
    "| **Casos de uso** | ML local, anal√≠tica exploratoria | Big Data, ETL distribuido, producci√≥n |\n",
    "| **Integraci√≥n distribuida** | Reciente, experimental | Madura, bien establecida |\n",
    "\n",
    "**Regla de oro:**\n",
    "- **Polars** cuando tus datos caben en memoria (y quieres m√°xima velocidad)\n",
    "- **Dask** cuando tus datos no caben en una m√°quina\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las bibliotecas de *Scipy* tienen limitaciones en cuanto a su capacidad de escalar de forma horizontal y a√∫n cuando son capaces de realizar *multithreading* para procesamiento en paralelo, est√°n restringidas a la cantidad de recursos disponibles de la m√°quina de las que son ejecutadas.\n",
    "\n",
    "[*Dask*](https://dask.org/) es una biblioteca general para c√≥mputo paralelo que permite escalar sus operaciones por medio de cl√∫sters (grupos de equipos de c√≥mputo que trabajan de forma coordinada).\n",
    "\n",
    "*Dask* consta de:\n",
    "\n",
    "* Un calendarizador de tareas din√°mico (*dynamic task scheduler*).\n",
    "* Una colecci√≥n de bibliotecas optimizadas para *Big Data*, con interfaces que extienden a*Numpy* y *Pandas*.\n",
    "\n",
    "https://docs.dask.org/en/stable/\n",
    "\n",
    "https://tutorial.dask.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principales paquetes de *Dask*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/arquitectura_dask.png\" width=75%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paquetes de colecciones de datos de *Dask*.\n",
    "\n",
    "* ```dask.array```, el cual contiene una biblioteca para manejo de arreglos similar a la de *Numpy*. Por convenci√≥n, este m√≥dulo se importa como ```da```. La documentaci√≥n de este paquete puede consultarse en:\n",
    " * https://docs.dask.org/en/stable/array.html\n",
    "* ```dask.dataframe```, el cual contiene una biblioteca para manejo de *dataframes* similar a la de *Pandas*. Por convenci√≥n, este m√≥dulo se importa como ```dd```. La documentaci√≥n de este paquete puede consultarse en:\n",
    " * https://docs.dask.org/en/stable/dataframe.html\n",
    "* ```dask.bags```, el cual contiene una biblioteca para manejo de *bags*, las cuales son estructuras de datos que pueden contener datos semi-estructurados y estructurados. Por convenci√≥n este m√≥dulo se importa como ```db```. La documentaci√≥n de este paquete puede consultarse en:\n",
    "https://docs.dask.org/en/stable/bag.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluaci√≥n perezosa (*lazy*) con el m√©todo ```compute()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv('data/data_covid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df[\"Nacional\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"Nacional\"].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Nacional\"] > 50000].loc[:, ['index', 'Nacional']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Nacional\"] > 50000].loc[:, ['index', 'Nacional']].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Persistencia en memoria con `persist()`.\n\nCon evaluaci√≥n perezosa, cada llamada a `compute()` **recalcula todo el grafo** desde el origen. Cuando el mismo DataFrame se reutiliza en m√∫ltiples operaciones, esto implica releer y reprocesar los datos innecesariamente.\n\n`persist()` ejecuta el grafo **una sola vez** y retiene los resultados en memoria, comport√°ndose como un cach√© distribuido.\n\n| Operaci√≥n | Comportamiento |\n|-----------|----------------|\n| `compute()` | Ejecuta el grafo y devuelve el resultado a Python |\n| `persist()` | Ejecuta el grafo y retiene el resultado en los workers |\n\nhttps://docs.dask.org/en/stable/api.html#dask.dataframe.DataFrame.persist",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import dask.dataframe as dd\n\ndf = dd.read_csv('data/data_covid.csv')\n\n# Sin persist: cada operaci√≥n relee y recalcula desde disco\nresultado_a = df[df['Nacional'] > 50000].compute()\nresultado_b = df['Nacional'].mean().compute()\n\n# Con persist: los datos se cargan una sola vez en memoria\ndf_cache = df.persist()\n\n# Las siguientes operaciones son m√°s r√°pidas ‚Äî los datos ya est√°n en memoria\nresultado_a = df_cache[df_cache['Nacional'] > 50000].compute()\nresultado_b = df_cache['Nacional'].mean().compute()\n\nprint(f\"Media Nacional: {resultado_b:.2f}\")\nprint(\"Resultados calculados con datos en cach√©.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotecas de *Dask*.\n",
    "\n",
    "* ```dask.delayed```. Esta biblioteca permite procesar colecciones basadas en *Python* de forma paralela.\n",
    " * https://docs.dask.org/en/stable/delayed.html\n",
    "* ```dask.futures```. Es una implementaci√≥n de [```concurrent.futures```](https://docs.python.org/3/library/concurrent.futures.html) de *Python* optimizado para correr en un cluster. La documentaci√≥n de este paquete puede consultarse en:\n",
    " * https://docs.dask.org/en/stable/futures.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Despliegue de un cluster con ```Dask.Distributed```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Dask* puede ser desplegado en clusters mediante el uso de varios equipos *workers* gestionados por un *scheduler*.\n",
    "\n",
    "\n",
    "https://distributed.dask.org/en/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/dask_cluster.png\" width=45%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install \"bokeh>=2.4.2, <3\"\n",
    "!pip install dask distributed --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dask scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integraci√≥n: Polars ‚Üí Dask (Escalado desde an√°lisis local)\n",
    "\n",
    "Un patr√≥n com√∫n en an√°lisis de datos es:\n",
    "1. **Explorar** datos con **Polars** en tu m√°quina (r√°pido)\n",
    "2. **Escalar** a **Dask** cuando necesites procesamiento distribuido\n",
    "\n",
    "Dask puede leer archivos Parquet generados por Polars de forma eficiente:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo: Leer Parquet escrito por Polars con Dask\n",
    "# df_dask = dd.read_parquet('data/mi_archivo.parquet')\n",
    "# \n",
    "# Ventajas:\n",
    "# - Parquet preserva tipos de datos de Polars\n",
    "# - Dask puede leer particiones en paralelo\n",
    "# - Sin conversi√≥n intermedia necesaria\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Procesamiento de datos particionados.\n\nEl **particionado Hive-style** organiza los archivos Parquet en subdirectorios seg√∫n el valor de una columna:\n\n```\ndatos/\n  region=norte/\n    part.0.parquet\n  region=sur/\n    part.0.parquet\n  region=este/\n    part.0.parquet\n```\n\nDask puede leer √∫nicamente las particiones necesarias (*partition pruning*), evitando leer archivos irrelevantes. Esto reduce significativamente el I/O en grandes vol√∫menes de datos.\n\nhttps://docs.dask.org/en/stable/dataframe-parquet.html",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import dask.dataframe as dd\nimport pandas as pd\n\n# Datos de ejemplo con columna de partici√≥n\ndf_ejemplo = pd.DataFrame({\n    'region':   ['norte', 'norte', 'sur', 'sur', 'este'],\n    'producto': ['A', 'B', 'A', 'C', 'B'],\n    'ventas':   [100, 200, 150, 300, 250]\n})\n\nddf = dd.from_pandas(df_ejemplo, npartitions=1)\n\n# Escribir particionado por 'region' (Hive-style)\nddf.to_parquet('data/ventas_particionadas/', partition_on=['region'], overwrite=True)\nprint(\"‚úì Datos escritos con particionado por regi√≥n\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Leer solo la regi√≥n 'norte' ‚Äî Dask no toca los dem√°s archivos (partition pruning)\ndf_norte = dd.read_parquet(\n    'data/ventas_particionadas/',\n    filters=[('region', '==', 'norte')]\n)\n\nprint(f\"Particiones le√≠das: {df_norte.npartitions}\")\nprint(df_norte.compute())",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso de uso: De Polars a Dask\n",
    "\n",
    "```python\n",
    "# Paso 1: Procesar con Polars (r√°pido, single-machine)\n",
    "import polars as pl\n",
    "df_polars = pl.read_csv('datos_grandes.csv')\n",
    "df_procesado = df_polars.filter(pl.col('fecha') > '2023-01-01')\n",
    "df_procesado.write_parquet('datos_procesados.parquet')\n",
    "\n",
    "# Paso 2: Distribuir con Dask si es necesario\n",
    "import dask.dataframe as dd\n",
    "df_dask = dd.read_parquet('datos_procesados.parquet')\n",
    "resultado = df_dask.groupby('categoria').agg({'valor': 'mean'}).compute()\n",
    "```\n",
    "\n",
    "**Ventajas de este enfoque:**\n",
    "- Polars maneja el preprocesamiento r√°pido\n",
    "- Dask escala el procesamiento distribuido\n",
    "- Parquet es el est√°ndar de facto para datos columnares\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center\"><a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Licencia Creative Commons\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/80x15.png\" /></a><br />Esta obra est√° bajo una <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Licencia Creative Commons Atribuci√≥n 4.0 Internacional</a>.</p>\n",
    "<p style=\"text-align: center\">&copy; Jos√© Luis Chiquete Valdivieso. 2017-2026.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}